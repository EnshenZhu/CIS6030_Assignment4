---
title: "R Notebook"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

library(ClusterR)
# unload all residual packages
invisible(lapply(paste0("package:", names(sessionInfo()$otherPkgs)),   # Unload add-on packages
                 detach,
                 character.only = TRUE, unload = TRUE))
```
```{r}
# install.packages("R6")
# install.packages("ClusterR")
# install.packages("cluster")
# install.packages("DescTools")
# install.packages("igraph")
# install.packages("dbscan")
# install.packages("r2r")
# install.packages("datastructures")

# Loading package
library(ClusterR)
library(cluster)
library(DescTools)
library(igraph)
import::from(R6, R6Class)
library(r2r)
```
k_param and MCS need be to declared manually, we declare them at very top
```{r}
k_param <- 3 # the core distance of a point is the distance from the point to the k-th nearest neighbour.
MCS <- 5 # minimum cluster size
```
```{r}
# import the iris data from the docker
result <- system("docker exec namenode hdfs dfs -cat ./input/iris.csv", intern = TRUE)
writeLines(result, "./hdbscan_manual/temp_iris.csv")
iris_data <- read.csv("./hdbscan_manual/temp_iris.csv",
                      header = FALSE,
                      colClasses = c(NA, NA, NA, NA, NA),
                      col.names = c("sepal_length", "sepal_width", "petal_length", "petal_width", "species"))
```
```{r}
# subtract the iris_params, which only contain the sepal and petal numberical values
iris_params <- iris_data[, -5]
iris_params
```

## Part 1 - Work out the core distance, mutual reachability distance and mutual reachability distance graph

```{r}
# create distance matrix for each data point pairs
L2_dist_matrix = as.matrix(dist(iris_params, method = "euclidean"))
L2_dist_matrix
```
```{r}
# caluclate the core ditance for each data point base on parameter k
core_dist <- apply(L2_dist_matrix, 1, FUN = function(x) Small(x, k = k_param + 1, unique = FALSE, na.last = NA)[k_param])

core_dist[1]
```
```{r}

# build the mutal distance matrix
dp_num = dim(iris_params)[1]
mutal_dist_matrix <- matrix(, nrow = dp_num, ncol = dp_num)

for (row_idx in 1:dp_num) {
  for (col_idx in 1:dp_num) {
    if (row_idx != col_idx) {
      #mutal distance is the max of (L2_dist(x,y), core_dist(x),core_dist(y))
      mutal_dist_matrix[row_idx, col_idx] <- max(L2_dist_matrix[row_idx, col_idx], core_dist[row_idx], core_dist[col_idx])
    }
    else {
      mutal_dist_matrix[row_idx, col_idx] = 0
    }
  }
}

# mutal_dist_matrix
```

## Part II Build the minimum spanning tree

```{r}
temp_graph = mutal_dist_matrix
# Step 1: Convert the matrix into the upper triangle matrix firstly
temp_graph[upper.tri(temp_graph)] <- 0

temp_graph_undirected <- as.undirected(graph.adjacency(temp_graph, weighted = TRUE))
graph_MST <- mst(temp_graph_undirected)
# graph_MST
```
```{r}
# Step 2: Turn back to the triangle matrix
temp_adjacent_matrix <- as_adjacency_matrix(graph_MST, type = "lower", attr = "weight")
MinimumSpanning_matrix <- matrix(temp_adjacent_matrix, nrow = dim(temp_adjacent_matrix)[1])
MinimumSpanning_matrix[upper.tri(MinimumSpanning_matrix)] <- 0
MinimumSpanning_matrix # Here is teh minimum spanning tree in the matrix format
```

## Part III
### Step0: Preset the class of the hieratical tree

```{r}
# MutualDistanceNode will be the internal nodes
TreeNodes <- R6Class("TreeNodes",
                     public = list(distance_val = NULL,
                                   leftNodeIdx = NULL,
                                   rightNodeIdx = NULL,

                                   selfIdx = NULL,
                                   parentNodeIdx = NULL,

                                   # The following fields are for the Condense and Extract
                                   hasChildren = list(),
                                   potentialNoise = FALSE,
                                   globalNoise = FALSE,
                                   lamda_birth = NULL,
                                   lamda_death = NULL,
                                   stability = numeric(),
                                   clusterBelongIdx = NULL,

                                   initialize = function(distance_val = NULL, left = NULL, right = NULL, selfIdx = NULL, parentNodeIdx = NULL) {

                                     self$distance_val = distance_val
                                     self$leftNodeIdx = left
                                     self$rightNodeIdx = right

                                     self$selfIdx = selfIdx
                                     self$parentNodeIdx = parentNodeIdx
                                   }
                     ))
```

### Step1: Get all edges, their corresponded element pairs, and sort them

```{r}
#RECALL dp_num should be the dimension size -> 150

# Create a distance dataFrame to store the (distance,x_coor,y_coor) info
N <- dp_num - 1 # pre-allocate the dp_num of rows <this might be overestimate> SHOULD BE 150 Lines
dist_DF <- data.frame(core_dist = rep(NA, N), point1_idx = rep(NA, N), point2_idx = rep(NA, N), # we need three columns
                      stringsAsFactors = FALSE) # you don't know levels yet

i <- 1
for (row_idx in 1:dp_num) {
  for (col_idx in 1:dp_num) {
    if (MinimumSpanning_matrix[row_idx, col_idx] != 0) {
      # add the (distance,x_coor,y_coor) to the dataFrame
      row_idx <- as.integer(row_idx)
      col_idx <- as.integer(col_idx)
      dist_DF[i,] <- list(MinimumSpanning_matrix[row_idx, col_idx], row_idx, col_idx)
      i <- i + 1
    }
  }
}

dist_DF <- dist_DF[order(dist_DF$core_dist),]
dist_DF

```
## Step2 Generate a hashmap to store all nodes (including leaf nodes and internal nodes
```{r}
allNode_Map <- hashmap()

for (idx in (-dp_num + 1):dp_num) {
  idx_char = as.character(idx)
  insert(allNode_Map, idx_char, TreeNodes$new(selfIdx = idx, parentNodeIdx = idx))

  if (idx > 0) { # when looping at leaf nodes
    temp_NodeObj <- query(allNode_Map, idx_char)
    temp_NodeObj$hasChildren <- append(temp_NodeObj$hasChildren, idx) # the children list to be itself
    temp_NodeObj$stability <- 0 # leaf node's stability should be 0
  }
}

testObj <- query(allNode_Map, "1")
testObj
```

## Step 3 Define the Union and Find functions

A. The following is the O(n) Find and O(1) Union

```{r}
FindNode <- function(x, allNode_Map) {
  # x -> TreeNode Class
  # allNode_Map -> hashmap

  if (x$parentNodeIdx == x$selfIdx) {
    return(x$selfIdx)
  }

  parentNode <- query(allNode_Map, as.character(x$parentNodeIdx))
  return(FindNode(parentNode, allNode_Map))
}

UnionNode <- function(targetIdx, x, y, allNode_Map) {
  # targetIdx -> int
  # x -> TreeNode Class
  # y -> TreeNode Class

  x$parentNodeIdx <- targetIdx
  y$parentNodeIdx <- targetIdx

  #store all corresponded leaf nodes from two children nodes
  tempObj <- query(allNode_Map, as.character(targetIdx))
  tempObj$hasChildren <- c(tempObj$hasChildren, x$hasChildren, y$hasChildren)
}
```

B. Iterate the dist_DF table to build the tree

```{r}
tracker <- 1 # tracking the dist_DF dataFrame table

for (idx in -1:(-dp_num + 1)) {
  the_dist <- dist_DF[tracker, 1]
  the_pointA_idx <- as.integer(dist_DF[tracker, 2])
  the_pointB_idx <- as.integer(dist_DF[tracker, 3])

  NodeObj <- query(allNode_Map, as.character(idx))

  # print(the_pointA_idx[[1]])
  # print(the_pointB_idx[[1]])

  NodeObj$distance_val <- the_dist

  # config the node object to be unioned
  the_pointA <- query(allNode_Map, as.character(the_pointA_idx))
  the_pointB <- query(allNode_Map, as.character(the_pointB_idx))

  NodeObj$leftNodeIdx <- FindNode(the_pointA, allNode_Map)
  NodeObj$rightNodeIdx <- FindNode(the_pointB, allNode_Map)

  leftNode <- query(allNode_Map, as.character(NodeObj$leftNodeIdx))
  rightNode <- query(allNode_Map, as.character(NodeObj$rightNodeIdx))

  UnionNode(targetIdx = idx, x = leftNode, y = rightNode, allNode_Map = allNode_Map)

  tracker <- tracker + 1

}

```
```{r}
# query(allNode_Map, "-148")
length(query(allNode_Map, "-148")$hasChildren)
# query(allNode_Map, "13")
```
## Step4 Do condense

Before start - when doing the Union Find, store all the corresponded Leaf Nodes and put them into the hasChildren list

A. Do the Level Order Traversal of the internal nodes of Hieratical Tree 进行层序遍历
Recall that the idx range of internal nodes are from -dp_num+1 to -1

B. Mark out the internal nodes which has the num of children less than MCS. They will become potential noise points

C. When doing the traversal, we also need to calculate the corresponded lamda (=1/distance)
```{r}
# datastructures seem to have conflict with the previous query method,
# so we import the library here rather than at top
library(datastructures)
```
```{r}
query(allNode_Map, "2")
```
```{r}
q <- queue() # for doing DFS (Level Order Traversal)

temp_NodeObj <- query(allNode_Map, as.character(-dp_num + 1))
q <- insert(q, temp_NodeObj)

while (size(q) > 0) {
  first_NodeObj <- peek(q) # get the first element of the queue

  first_NodeObj$lamda_birth = 0 # 有问题

  if (first_NodeObj$selfIdx < 0) { # we are only going to process internal nodes (idx<0)
    # mark it as the potentialNoise if its nums of children is smaller than MCS
    if (length(first_NodeObj$hasChildren) < MCS) {
      first_NodeObj$potentialNoise <- TRUE
      # print(first_NodeObj$selfIdx)
    }

    first_NodeObj$lamda_birth <- (1 / first_NodeObj$distance_val) # record the lamda_birth # 有问题

    next_leftNodeIdx <- first_NodeObj$leftNodeIdx
    next_leftNode <- query(allNode_Map, as.character(next_leftNodeIdx))
    q <- insert(q, next_leftNode)

    next_rightNodeIdx <- first_NodeObj$rightNodeIdx
    next_rightNode <- query(allNode_Map, as.character(next_rightNodeIdx))
    q <- insert(q, next_rightNode)
  }

  pop(q)
}

```
```{r}
query(allNode_Map, "2")
```
## Step 5 Do Extract
### A. Create a nodeExtractWork function
* For leaf node, lambda_death = lambda_birth
* For internal node, if it is not potential outlier -> Lambda_death = (num_children )* (left_child_lambda_brith);
* else Lambda_death = left_child_death + right_child_death
```{r}
nodeExtractWork <- function(the_Node_idx, allNode_Map) {

  the_Node <- query(allNode_Map, as.character(the_Node_idx))

  # visit the left and right node
  the_leftNode <- query(allNode_Map, as.character(the_Node$leftNodeIdx))
  the_rightNode <- query(allNode_Map, as.character(the_Node$rightNodeIdx))

  # print(the_leftNode$stability)
  # print(the_rightNode$stability)

  # section 1 Calculate Node lambda_death for each internal node
  if (the_Node$selfIdx > 0) { # if the node is a leaf node
    the_Node$lamda_death = the_Node$lamda_birth
  }
  else { # if the node is an internal node

    # For internal node, if it is not potential outlier -> Lambda_death = (num_children )* (left_child_lambda_brith);
    if (the_leftNode$potentialNoise == FALSE & the_rightNode$potentialNoise == FALSE) {
      the_Node$lamda_death = (length(the_Node$hasChildren) * the_leftNode$lamda_birth)
    }

      # if one of the child node is a potential outlier, Lambda_death = left_child_death + right_child_death
    else {
      the_Node$lamda_death = the_leftNode$lamda_death + the_rightNode$lamda_death
    }
  }

  # section 2 Calculate Internal Node Stability
  if (the_Node$selfIdx < 0) {
    the_Node$stability <- the_Node$lamda_death - length(the_Node$hasChildren) * the_Node$lamda_birth
  }

  print(length(the_Node$hasChildren))
  print(the_Node$lamda_death)

  # section 3 Extract and find global noise
  if (the_Node$selfIdx > 0) { # for leaf nodes, their stability will always be 0
    the_Node$stability = 0
  }
  else { # for internal nodes
    if (the_Node$stability >= the_leftNode$stability + the_rightNode$stability) {

      the_Node$stability = the_Node$stability

      # if merge is more stable, we mark the two children into the same cluster idx
      the_leftNode$clusterBelongIdx <- the_Node$selfIdx
      the_rightNode$clusterBelongIdx <- the_Node$selfIdx
    }
    else {
      # if split is more stable, the child node will be marked as the global noise as long as it is previously labelled as the potential outlier

      the_Node$stability = the_leftNode$stability + the_rightNode$stability

      # handle left child
      if (the_leftNode$potentialNoise == TRUE) {
        the_leftNode$clusterBelongIdx <- 0
        the_leftNode$globalNoise <- TRUE
      }
      else {
        the_leftNode$clusterBelongIdx <- the_leftNode$selfIdx
      }

      # handle right child
      if (the_rightNode$potentialNoise == TRUE) {
        the_rightNode$clusterBelongIdx <- 0
        the_rightNode$globalNoise <- TRUE
      }
      else {
        the_rightNode$clusterBelongIdx <- the_rightNode$selfIdx
      }
    }
  }
}
```
### B. Create A postorder traversal function (we use recursive design in this case)
```{r}
# In recursion
posOrderRecur <- function(root, allNode_Map, cache) {

  # root -> TreeNode
  if (!is.null(root)) {

    # visit the left node
    the_leftNode <- query(allNode_Map, as.character(root$leftNodeIdx))
    cache <- posOrderRecur(the_leftNode, allNode_Map, cache)

    # visit the right node
    the_rightNode <- query(allNode_Map, as.character(root$rightNodeIdx))
    cache <- posOrderRecur(the_rightNode, allNode_Map, cache)

    # print(root$selfIdx)
    print(root$selfIdx)
    cache <- append(cache, root$selfIdx)
  }

  return(cache)

}

```
```{r}
theCache <- list()
start_root <- query(allNode_Map, as.character(-1))
theCache <- posOrderRecur(start_root, allNode_Map, theCache)
# posOrderRecur2(start_root, allNode_Map)
# length(theCache)
```
Now we are going to execute the node extraction
```{r}
for (idx in theCache) {
  nodeExtractWork(idx, allNode_Map)
}
```
```{r}
query(allNode_Map, "1")$lamda_death
isTRUE(query(allNode_Map, "-1")$stability)
```
